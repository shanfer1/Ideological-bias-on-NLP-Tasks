# -*- coding: utf-8 -*-
"""Random Forest.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ooZuca5Svc89o1nAFXfF93EWFzIi1kbf
"""

import pandas as pd
import nltk
nltk.download('stopwords')
nltk.download('punkt')
nltk.download('wordnet')
nltk.download('omw-1.4')
from nltk.stem.porter import PorterStemmer
stemmer = PorterStemmer()
from nltk.corpus import stopwords
stop_list = set(stopwords.words('english'))
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
import seaborn as sns

from nltk.stem import WordNetLemmatizer
lemmatizer = WordNetLemmatizer()
def text_preprocess(value):
    value['text'] = value['text'].str.lower() #lowercase all words
    value['text']=value['text'].str.split().map(lambda sl: " ".join(s for s in sl if len(s) > 2)) #remove word less than 2 char
    value['text'] = value['text'].str.replace(r'\d+','') #removing numbers
    value['text'] = value['text'].str.replace(r'[ ](?=[ ])|[^-_,A-Za-z0-9 ]+', "") #removing special characters 
    value['tokenized_sentences'] = value.apply(lambda row: nltk.word_tokenize(row['text']), axis=1)
    value['tokenized_sentences']= value['tokenized_sentences'].apply(lambda x: [item for item in x if item not in stop_list]) #removing stopwords
    value['tokenized_sentences'] = value['tokenized_sentences'].apply(lambda x : [stemmer.stem(y) for y in x]) #stemming 
    value['tokenized_sentences'] = value['tokenized_sentences'].apply(lambda x : [lemmatizer.lemmatize(y) for y in x]) #lemmatizing 
    value['clean_text'] = value['tokenized_sentences'].str.join(' ') #converting back to normal string from tokenized string 
    return value

from sklearn.preprocessing import LabelEncoder

def encode_topic(dataframe):
    encoder = LabelEncoder()
    dataframe['topicEncoded'] = encoder.fit_transform(dataframe['topic'])
    dataframe['text'] = dataframe['text'].apply(lambda text: str(text).lower())
    return dataframe

df_cnn=pd.read_csv('./data/nov_23_df_cnn_topic_combined.csv')
df_cnn.head()

plt.figure(figsize=(12,5))
sns.countplot(x=df_cnn.topic, color='yellow')
plt.title('Tweets Topics Distribution', fontsize=16)
plt.ylabel('Number of Tweets', fontsize=16)
plt.xlabel('Topic', fontsize=16)
plt.xticks(rotation='vertical');

df_fox=pd.read_csv('./data/nov_23_df_fox_topic_combined.csv')
df_fox.head()

df_reuters=pd.read_csv('./data/nov_23_df_reuters_topic_combined.csv')
df_reuters.head()

print(df_cnn.shape)
print(df_fox.shape)
print(df_reuters.shape)

"""#Encoding the topic"""

df_cnn=encode_topic(df_cnn)
df_fox=encode_topic(df_fox)
df_reuters=encode_topic(df_reuters)

"""#clean the tweet text: Data Preprocessing """

df_cnn = text_preprocess(df_cnn)
df_fox = text_preprocess(df_fox)
df_reuters=text_preprocess(df_reuters)

"""#saving the preprocessed dataset, wil be using this in the future"""

df_cnn.to_csv('./data/preprocessed_nov_23_df_cnn_topic_combined.csv')
df_fox.to_csv('./data/preprocessed_nov_23_df_fox_topic_combined.csv')
df_reuters.to_csv('./data/preprocessed_nov_23_df_reuters_topic_combined.csv')

"""#Vectoriser"""

v = TfidfVectorizer(max_features=2500) #Initializnig the TF-IDF Vectorizer

"""#Defining the independent and dependent vectors for all three datasets"""

X_left = v.fit_transform(df_cnn['clean_text']).toarray()
X_right= v.fit_transform(df_fox['clean_text']).toarray()
X_neutral=v.fit_transform(df_reuters['clean_text']).toarray()
y_left=df_cnn['topicEncoded']
y_right=df_fox['topicEncoded']
y_nuetral=df_reuters['topicEncoded']

print(X_left.shape)
print(X_right.shape)
print(X_neutral.shape)

df_cnn['topicEncoded'].value_counts()

df_fox['topicEncoded'].value_counts()

df_reuters['topicEncoded'].value_counts()

def print_evaluators(test,pred):
    print(classification_report(test,pred)) #Using classification_report function to get the summary of how good the classifier is 
    print(accuracy_score(test, pred)) #Using accuracy_score function to get the overall accuracy

"""# training it on left and testing it on right"""

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

classifier_auto.fit(X_left, y_left)

print(X_left.shape)
print(y_left.shape)

# from yellowbrick.model_selection import learning_curve
# print(learning_curve(RandomForestClassifier(n_estimators=1000, random_state=0) , X_left, y_left, cv=10, scoring='accuracy'))

y_pred_right = classifier_auto.predict(X_right)


print("train it on the left and test it on the right")
print_evaluators(y_right,y_pred_right)

"""# Training it on the left and testing it on the nuetral"""

y_pred_nuetral = classifier_auto.predict(X_neutral)

print("train on the left and test on the neutral")
print_evaluators(y_nuetral,y_pred_nuetral)

"""# Training on Left and testing it on left"""

from sklearn.model_selection import train_test_split
X_left_train, X_left_test , y_left_train, y_left_test = train_test_split(X_left, y_left , test_size = 0.30)

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

classifier_auto.fit(X_left_train, y_left_train)

y_pred_left = classifier_auto.predict(X_left_test)

print("train on the left and test it on the left")
print_evaluators(y_left_test,y_pred_left)

"""# Training it on the nuetral data and testing it on the nuetral data"""

X_nuetral=X_neutral

from sklearn.model_selection import train_test_split
X_nuetral_train, X_nuetral_test , y_nuetral_train, y_nuetral_test = train_test_split(X_nuetral, y_nuetral , test_size = 0.30)

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

# from yellowbrick.model_selection import learning_curve
# print(learning_curve(RandomForestClassifier(n_estimators=1000, random_state=0) , X_nuetral, y_nuetral, cv=10, scoring='accuracy'))

classifier_auto.fit(X_nuetral_train, y_nuetral_train)

y_pred_nuetral = classifier_auto.predict(X_nuetral_test)

print("train on the nuetral and test it on the nuetral data")
print_evaluators(y_nuetral_test,y_pred_nuetral)

"""# Training it on the nuetral data and test it on the left data"""

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

classifier_auto.fit(X_nuetral, y_nuetral)

y_pred_left = classifier_auto.predict(X_left)

print("Training it on the nuetral data and test it on the left data")
print_evaluators(y_left,y_pred_left)

"""# Training it on the nuetral and test it on the right data"""

y_pred_right = classifier_auto.predict(X_right)

print("Training it on the nuetral and test it on the right data")
print_evaluators(y_right,y_pred_right)

"""# Training it on Right and test it on left"""

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

classifier_auto.fit(X_right, y_right)

y_pred_left = classifier_auto.predict(X_left)
print("Training it on Right and test it on left")
print_evaluators(y_left,y_pred_left)

"""# Training it on right and test it on nuetral data"""

y_pred_nuetral = classifier_auto.predict(X_nuetral)

print("Training it on right and test it on nuetral data")
print_evaluators(y_nuetral,y_pred_nuetral)

"""# Training it on right side and test it on the right side"""

from sklearn.model_selection import train_test_split
X_right_train, X_right_test , y_right_train, y_right_test = train_test_split(X_right, y_right , test_size = 0.30)

from sklearn.ensemble import RandomForestClassifier

classifier_auto = RandomForestClassifier(n_estimators=1000, random_state=0) #Initializing classifier

# from yellowbrick.model_selection import learning_curve
# print(learning_curve(RandomForestClassifier(n_estimators=1000, random_state=0) , X_right, y_right, cv=10, scoring='accuracy'))

classifier_auto.fit(X_right_train, y_right_train)

y_pred_right = classifier_auto.predict(X_right_test)

print("Training it on right side and test it on the right side")
print_evaluators(y_right_test,y_pred_right)





